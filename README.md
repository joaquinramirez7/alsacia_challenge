# **Boston Housing Prices Prediction**

## **Descripci贸n del Proyecto **

Este proyecto tiene como objetivo **predecir el valor medio de las viviendas** ocupadas por sus propietarios en Boston. Es un **problema de regresi贸n supervisada**, donde se utiliza el **Error Cuadr谩tico Medio (RMSE)** como m茅trica de desempe帽o. La predicci贸n de los precios se realiza a partir de diversas caracter铆sticas del vecindario, como la tasa de criminalidad, la proximidad a carreteras, el n煤mero de habitaciones, entre otras.

Variables:
- **CRIM:** tasa de criminalidad per c谩pita por ciudad
- **ZN:** proporci贸n de tierras residenciales zonificadas para lotes mayores a 25,000 pies cuadrados
- **INDUS:** proporci贸n de acres de negocios no comerciales por ciudad
- **CHAS:** variable dummy para el r铆o Charles (= 1 si el distrito limita con el r铆o; 0 en caso contrario)
- **NOX:** concentraci贸n de 贸xidos de nitr贸geno (partes por 10 millones)
- **RM:** n煤mero promedio de habitaciones por vivienda
- **AGE:** proporci贸n de unidades ocupadas por sus propietarios construidas antes de 1940
- **DIS:** distancias ponderadas a cinco centros de empleo de Boston
- **RAD:** 铆ndice de accesibilidad a carreteras radiales
- **TAX:** tasa impositiva de propiedad sobre el valor total por cada $10,000
- **PTRATIO:** proporci贸n de alumnos por profesor por ciudad
- **B:** 1000(Bk - 0.63)^2 donde Bk es la proporci贸n de negros por ciudad
- **LSTAT:** porcentaje de poblaci贸n de estatus bajo
- **MEDV:** valor medio de las viviendas ocupadas por sus propietarios en miles de d贸lares


## **Resumen del problema**

### **1. An谩lisis Exploratorio de Datos**
Se comienza con un an谩lisis preliminar para comprender las caracter铆sticas del conjunto de datos y las relaciones entre ellas:
- Identificaci贸n de valores faltantes.
- An谩lisis de tipos de datos de cada feature.
- Detecci贸n y manejo de **outliers**.
- An谩lisis de **correlaciones** con el valor de las viviendas (target).

### **2. Preprocesamiento de Datos**
Se crean dos versiones del conjunto de datos:
- **Con outliers eliminados** de ciertos **features**.
- **Sin eliminar outliers**, para observar el impacto de su presencia en los modelos.

### **3. Entrenamiento de Modelos**
Se entrenan diversos modelos de regresi贸n para abordar el problema de la predicci贸n:
- **Regresi贸n Lineal**
- **Regresi贸n Polin贸mica de Segundo Grado**
- **Random Forest**
- **Gradient Boosting**
- **Ensamble de Random Forest y Gradient Boosting**

Los modelos de regresi贸n lineal y polin贸mica se entrenan sobre **ambos conjuntos de datos** (con y sin outliers).

### **4. Evaluaci贸n de Modelos**
Todos los modelos se eval煤an utilizando el conjunto de prueba, y se comparan sus desempe帽os en base al **RMSE**.

Resultados obtenidos en conjunto de test:

- **Regresion Lineal**: 4.69
- **Regresion Polinomica**: 4.91
- **Random Forest (hiperparametros por defecto)**: 3.73
- **Gradient Boosting (hiperparametros por defecto)**: 3.86
- **Random Forest (tuneo de hiperparametros)**: 4.01
- **Gradient Boosting (tuneo de hiperparametros)**: 3.86
- **Ensamble (Random Forest (tuneo de hiperparametros) + Gradient Boosting (tuneo de hiperparametros))**: 4.04

### **5. Observaciones**: 
- El modelo **Random Forest (hiperparametros por defecto)** muestra el **mejor desempe帽o**, con un **RMSE de 3.73**, lo que representa aproximadamente el **15%** del valor medio de las viviendas en el dataset.
- No se observan mejoras al entrenar los modelos de regresion lineal y polinomica de segundo grado con el conjunto de datos sin outliers.
- No se observan mejoras significativas en los resultados obtenidos para los modelos con ajuste de hiperparametros.

### **6. Conclusiones**:
- El valor obtenido para el modelo de Random Forest es bastante decente, considerando el margen de valores que se manejan para el feature objetivo y la cantidad reducida de datos que se usan para entrenar el modelo. Tal vez, probando otras estrategias, como ajuste mas preciso de hiperparametros, o combinacion de otros modelos en ensamble se podr铆a haber obtenido un mejor desempe帽o.
- El hecho de que los modelos con hiperparametros por defecto superara a los modelos con tuneo de hiperparametros indica que la seleccion de hiperparmetros puede no haber sido optima. Deber铆a analizarse este resultado y continuar haciendo pruebas con nuevos valores, tal vez en rangos cercanos a los predeterminados.
- La estrategia implementada para eliminar outliers no arroj贸 los resultados esperados. Se podr铆an abordar otras estrategias, implementando por ejemplo IQR junto con transformaciones de los features.
- Si bien no se hizo seleccion de caracteristicas, durante el an谩lisis exploratorio de los datos, se observ贸 que algunas caracter铆sticas ten铆an una fuerte correlaci贸n con el valor de las viviendas (MEDV), lo que implica que ciertas variables son cruciales para las predicciones.
- El uso de estrategias como CrossValidation permiten tener una vision mas completa del desempe帽o de los modelos, sobre todo en casos como este que se trabaja con un conjunto de datos reducido.


## **Estructura del Repositorio **

- **`model_training.ipynb`**: Notebook con todo el proceso de an谩lisis, preprocesamiento, y entrenamiento de modelos. Permite realizar el entrenamiento y evaluar los modelos.
- **`best_model.ipynb`**: Notebook con el mejor modelo (Gradient Boosting) entrenado, donde se puede ejecutar sobre el conjunto completo de datos para evaluar su desempe帽o final.
- **`requirements.txt`**: Lista de los paquetes y bibliotecas necesarios para ejecutar los notebooks.
- **`gradientBoosting.joblib`**: Archivo que contiene el mejor modelo entrenado. Se utiliza en **best_model.ipynb** para hacer predicciones sobre el dataset.
- **`README.md`**: Instrucciones del proyecto.


## **C贸mo Ejecutar los Notebooks**

1. **Instalar los requerimientos:**
    Correr **pip install -r requirements.txt** sobre el entorno desde el que se vaya a trabajar.

2. **Notebooks:**
    Si bien los notebooks fueron ejecutados, se pueden correr nuevamente para validar los resultados.



